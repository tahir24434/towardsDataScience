{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b5d197a-283e-476f-a512-baa907ec9132",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Under the Hood: Training a Digit Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d8410-2d30-44ae-836c-1009aa6e8394",
   "metadata": {},
   "source": [
    "## Pixels: The Foundations of Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3d3df2-09d9-4a55-961c-605091dfcfb9",
   "metadata": {},
   "source": [
    "In order to understand what happens in a computer vision model, we first have to understand how computers handle images.\n",
    "We are going to try to create a model that can classify any image as 3 or 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0b551-0517-46b5-bccb-d9a52ee39aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d8b8d-6efb-4059-a68d-07026903e637",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To download any of the datasets or pretrained weights, simply run untar_data by passing any dataset name mentioned above like so:\n",
    "#    path = untar_data(URLs.PETS)\n",
    "# For details: https://docs.fast.ai/data.external.html\n",
    "\n",
    "# Download sample of MNIST that contains images of just these digits\n",
    "\n",
    "path = untar_data(URLs.MNIST_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f692b3-404c-4e09-bc52-640c5b5d41d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can see what is in the directory by using 'ls'.\n",
    "# MNIST dataset followed common layout for machine learning dataset: seperate folder for the training set and the validation set. \n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e1e747-ad62-42fb-8866-3262d067df95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7688c9d2-5722-467b-99c8-cccf734b8624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa687a1b-eca9-47b7-a21e-840651fe3d23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "im3 = Image.open(threes[1])                  # Use image class from Python imaging library\n",
    "im3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c84de0-8d7e-41e8-874a-9e8d2be18a96",
   "metadata": {},
   "source": [
    "In a computer, everything is represented as a number. To view the numbers that make up this image, we have to convert it to a *NumPy array* or a *PyTorch tensor*. For instance, here's what a section of the image looks like, converted to a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a90aa2-1535-4493-a089-662d94203743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "array(im3)[4:15,4:22]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5716db-9159-4a59-9dea-22f6433834b5",
   "metadata": {},
   "source": [
    "We can use a Pandas DataFrame to color-code the values using a gradient, which shows us clearly how the image is created from the pixel values.You can see that the background white pixels are stored as the number 0, black is the number 255, and shades of gray are between the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2f3b50-251d-4574-b7a8-207e8e85b6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide_output\n",
    "im3_t = tensor(im3)\n",
    "df = pd.DataFrame(im3_t[4:15,4:22])\n",
    "df.style.set_properties(**{'font-size':'6pt'}).background_gradient('Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049863e4-dde9-4947-a5ff-ea5cb6e69e7d",
   "metadata": {},
   "source": [
    "So, now you've seen what an image looks like to a computer, let's recall our goal: create a model that can recognize 3s and 7s. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3812c3e6-f42e-4aa4-9db6-1606580ed345",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First Try: Pixel Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b998cb0-0d73-47a5-9bdc-07cfa3981c67",
   "metadata": {},
   "source": [
    "How about we find the average pixel value for every pixel of the 3s, then do the same for the 7s. This will give us two group averages, defining what we might call the \"ideal\" 3 and 7. Then, to classify an image as one digit or the other, we see which of these two ideal digits the image is most similar to. This certainly seems like it should be better than nothing, so it will make a good baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ee0416-349f-4c27-9ccf-9d174d3d9f70",
   "metadata": {},
   "source": [
    "> jargon: Baseline: A simple model which you are confident should perform reasonably well. It should be very simple to implement, and very easy to test, so that you can then test each of your improved ideas, and make sure they are always better than your baseline. Without starting with a sensible baseline, it is very difficult to know whether your super-fancy models are actually any good. One good approach to creating a baseline is doing what we have done here: think of a simple, easy-to-implement model. Another good approach is to search around to find other people that have solved similar problems to yours, and download and run their code on your dataset. Ideally, try both of these!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6917db8d-8239-4d0b-a3cd-843bf94af284",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "print(three_tensors[0].shape)\n",
    "len(three_tensors),len(seven_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27beb83b-c16e-41d9-8764-5f2cd27e9943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check how a single image looks like\n",
    "show_image(three_tensors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69eeadb9-4ee4-409e-a67e-073b1e9fd0c5",
   "metadata": {},
   "source": [
    "For every pixel position, we want to compute the average over all the images of the intensity of that pixel. To do this, we first combine all the images in this list into a single three-dimensional tensor. The most common way to describe such a tensor is to call it a *rank-3 tensor*. We often need to stack up individual tensors in a collection into a single tensor. \n",
    "Unsurprisingly, PyTorch comes with a function called `stack` that we can use for this purpose.\n",
    "'mean' require us to *cast* our integer types to float types. Generally when images are floats, the pixel values are expected to be between 0 and 1, so we will also divide by 255 here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a4e4c0-4c9c-45d2-a75e-359cebbc1635",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stack up individual tensors in a collection into a single tensor.\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c2295-de25-43fd-a46b-32e2c5785396",
   "metadata": {},
   "source": [
    "**RANK** is the number of axes or dimensions in a tensor. <br>\n",
    "**SHAPE** is the size of each axis of a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e433e5-bc84-4cf5-954b-8b08b378c0e6",
   "metadata": {},
   "source": [
    "We can get a tensor's rank with ndim or len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664bec95-529c-4dee-836e-5e80095876ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(stacked_threes.shape))\n",
    "print(stacked_threes.ndim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960be31f-0567-4c7c-9b10-29cfcaac4259",
   "metadata": {},
   "source": [
    "Finally, we can compute what the ideal 3 looks like. For every pixel position, we'll compute the average of that pixel over all images. The result will be one value for every pixel position, or a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374484da-6164-407d-a295-b589fcb01543",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean3 = stacked_threes.mean(0)\n",
    "show_image(mean3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09277b-64ca-49d0-8d2d-98ff91dae5b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean7 = stacked_sevens.mean(0)\n",
    "show_image(mean7);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f648c93-59fe-4aa2-948b-bef407949041",
   "metadata": {},
   "source": [
    "Let's now pick an arbitrary 3 and measure its *distance* from our \"ideal digits\". \n",
    "We'll see that in both cases, the distance between our 3 and the \"ideal\" 3 is less than the distance to the ideal 7. So our simple model will give the right prediction in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044b4ec-3e8f-4127-a7dc-0d54d5e69d07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist_3_abs = (stacked_threes[1] - mean3).abs().mean()\n",
    "dist_3_sqr = ((stacked_threes[1] - mean3)**2).mean().sqrt()\n",
    "dist_3_abs,dist_3_sqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f788e29-251f-47b1-97c9-47ddd724da95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dist_7_abs = (stacked_threes[1] - mean7).abs().mean()\n",
    "dist_7_sqr = ((stacked_threes[1] - mean7)**2).mean().sqrt()\n",
    "dist_7_abs,dist_7_sqr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55def46-85be-4e71-9835-9e17039f2a60",
   "metadata": {},
   "source": [
    "PyTorch already provides both of these as *loss functions*. You'll find these inside `torch.nn.functional`, which the PyTorch team recommends importing as `F` (and is available by default under that name in fastai):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2722df26-3742-4ab4-b196-6798a2e9a032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# l1 refers to the standard mathematical jargon for mean absolute value (In math it \n",
    "# is called the L1 norm)\n",
    "# 'mse' stands for MeanSquaredError.\n",
    "F.l1_loss(stacked_threes[1].float(), mean7), F.mse_loss(stacked_threes[1], mean7).sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071de90-37b7-451c-b138-180c8c2044fa",
   "metadata": {},
   "source": [
    "### PyTorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23dfd987-4599-46d1-88e3-6195863af70e",
   "metadata": {},
   "source": [
    "A tensor is container of data, almost always numerical data. You may be already familiar with matrices, which are 2D tensors: tensors are a generalaization of matrices to an arbitrary number of dimensions (often called *axis*). \n",
    "e.g Scalar (0D tensors), Vectors(1D tensors), Matrices(2D tensors). If you pack matrices in a new array, you obtain a 3D tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4144a6-6334-49d8-bade-337005b293d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.array([\n",
    "    [\n",
    "      [1, 2],\n",
    "      [3, 4]\n",
    "    ],\n",
    "    [\n",
    "      [1, 2],\n",
    "      [3, 4]\n",
    "    ]\n",
    "])\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be0e240-f7e5-48b3-ac21-4f8287001694",
   "metadata": {
    "tags": []
   },
   "source": [
    "A tensor is defined by 3 key attributes\n",
    "1. Rank  - Number of axes \n",
    "2. Shape - Length of each axis\n",
    "3. DataType - Type of the data contained in Tensor. \n",
    "In general, the first axis in all dataTensors you'll come across in deep learning will be the *sample axis* (sometimes called the *samples dimension*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856d5955-84dc-455c-8f15-39f251b12e65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stacked_threes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8747c03-711a-4fea-b934-d98fe80b5c30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = [[1,2,3],[4,5,6], [7,8,9]]\n",
    "tns = tensor(data)         \n",
    "tns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556327b-5d99-46d5-a583-e3266be848ab",
   "metadata": {},
   "source": [
    "Select a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0ea371-8e66-40c5-b14f-12a81c6a83b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tns[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59a7bfc-24cf-4481-acd0-6317dc22656f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Select a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cd8435-728b-4d94-ac83-64979ed50e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tns[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e5d828-424b-4c78-9b53-dd98ec930df4",
   "metadata": {},
   "source": [
    "You can combine these with Python slice syntax ([start:end] with end being excluded) to select part of a row or column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890b74f-f3df-4b87-aa79-11181d213d69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tns[1, 1:3] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed5f250-b738-4704-8cc5-0587ac1c3155",
   "metadata": {},
   "source": [
    "use the standard operators such as +, -, *, /:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e611105-77c4-4099-836c-dc5a5e3597f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tns+1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7b4ab7-4027-43c7-821d-8165a7da0a28",
   "metadata": {},
   "source": [
    "And will automatically change type as needed, for example from `int` to `float`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fffc632-c43c-4348-85a1-4ecba384094f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tns.type())\n",
    "tns1 = tns*1.5\n",
    "print(tns1.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06850da-016f-46ec-9922-e3c838ed3715",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Computing Metrics Using Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4eddaa-2692-4e2d-8322-d26766ae286a",
   "metadata": {},
   "source": [
    "Recall that a metric is a measurement of how good the model is using the validation set, chosen for human consumption. This is a number that is calculated based on the prediction of our model, and the correct labels in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dbf148-59ee-4c13-95ff-eea16e7d333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_threes = (path/'valid'/'3').ls().sorted()\n",
    "valid_sevens = (path/'valid'/'7').ls().sorted()\n",
    "valid_three_tensors = [tensor(Image.open(o)) for o in valid_threes]\n",
    "valid_seven_tensors = [tensor(Image.open(o)) for o in valid_sevens]\n",
    "\n",
    "valid_stacked_threes = torch.stack(valid_three_tensors).float()/255\n",
    "valid_stacked_sevens = torch.stack(valid_seven_tensors).float()/255\n",
    "# 3s validation set of 1,010 images of size 28×28, \n",
    "# 7s validation set of 1,028 images of size 28×28.\n",
    "valid_stacked_threes.shape, valid_stacked_sevens.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997c466c-0ffb-4604-a0fa-a266eab94aab",
   "metadata": {},
   "source": [
    "Write a function that calculated mean absolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dc8c3b-8427-4e05-b2c8-97dcc61f92e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mnist_distance(a, b):\n",
    "    return (a-b).abs().mean((-1,-2))\n",
    "# Calculate distance between arbitrary three and 'ideal' three mean3.\n",
    "# Recall that mean3 was calculated using stacked tensors of threes of training set \n",
    "# and calculating mean value of each pixel. \n",
    "mnist_distance(stacked_threes[1], mean3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161bfd30-eaa8-4104-8935-d7591eb5a2d6",
   "metadata": {},
   "source": [
    "In order to calculate a metric for overall accuracy, we'll need to calculate the distance to the ideal 3 for _every_ image in the validation set. \n",
    "We can use the 'mnist_distance()' fucntion, designed for comparing two single images, but pass in as argument valid_stacked_threes. Instead of complaining about shapes not matching, it returned the distance for every single image as a vector (a rank-1 tensor). See Appendix for details around 'broadcast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531b5ecf-2754-4c1c-8dcf-1b1ee0d49e33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_3_dist = mnist_distance(valid_stacked_threes, mean3)\n",
    "valid_3_dist, valid_3_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a521709c-49c3-4049-b45c-01029ed33bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(valid_stacked_threes - mean3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401d152b-d62b-45b5-8fce-e5a318c78477",
   "metadata": {},
   "source": [
    "To figure out whether an image is a 3 or not by using the following logic: if the distance between the digit in question and the ideal 3 is less than the distance to the ideal 7, then it's a 3. This function will automatically do broadcasting and be applied elementwise, just like all PyTorch functions and operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e52ea41-a34b-4b38-b536-8d8271390a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_3(x): \n",
    "    return mnist_distance(x,mean3) < mnist_distance(x,mean7)\n",
    "print(is_3(stacked_threes[1]), is_3(stacked_threes[1]).float())\n",
    "print(is_3(stacked_sevens[1]), is_3(stacked_sevens[1]).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2dc2dc-d296-45c1-a1d4-efe162f4f1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy_3s =      is_3(valid_stacked_threes).float() .mean()\n",
    "accuracy_7s = (1 - is_3(valid_stacked_sevens).float()).mean()\n",
    "\n",
    "accuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a46c04-583d-432e-98d7-5630ccfd3de2",
   "metadata": {},
   "source": [
    "This looks like a pretty good start! We're getting over 90% accuracy on both 3s and 7s, and we've seen how to define a metric conveniently using broadcasting.\n",
    "\n",
    "But let's be honest: 3s and 7s are very different-looking digits. And we're only classifying 2 out of the 10 possible digits so far. So we're going to need to do better!\n",
    "\n",
    "To do better, perhaps it is time to try a system that does some real learning—that is, that can automatically modify itself to improve its performance. In other words, it's time to talk about the training process, and SGD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5668a469-e5bf-4b69-9b03-d50938eb00ad",
   "metadata": {},
   "source": [
    "#### Appendix A: Broadcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08e6c42-e776-4517-ac5a-bb6fc5ace0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_distance(a, b):\n",
    "    return (a-b).abs().mean((-1,-2))\n",
    "valid_3_dist = mnist_distance(valid_stacked_threes, mean3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e56b599-ad2a-43cc-ac36-843659e4bb3d",
   "metadata": {},
   "source": [
    "Instead of complaining about shapes not matching, it returned the distance for every single image as a vector (a rank-1 tensor)\n",
    "The magic trick is that PyTorch, when it tries to perform a simple subtraction operation between two tensors of different ranks, will use broadcasting. That is, it will automatically expand the tensor with the smaller rank to have the same size as the one with the larger rank. After broadcasting so the two argument tensors have the same rank, PyTorch applies its usual logic for two tensors of the same rank: it performs the operation on each corresponding element of the two tensors, and returns the tensor result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0085ec8-4d9c-4702-9f9c-1e13d430b56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor([1,2,3]) + tensor(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2f9cb0-a0a1-4637-bd53-09f01d4c42c5",
   "metadata": {},
   "source": [
    "There are a couple of important points about how broadcasting is implemented, which make it valuable not just for expressivity but also for performance:\n",
    "\n",
    "- PyTorch doesn't *actually* copy `mean3` 1,010 times. It *pretends* it were a tensor of that shape, but doesn't actually allocate any additional memory\n",
    "- It does the whole calculation in C (or, if you're using a GPU, in CUDA, the equivalent of C on the GPU), tens of thousands of times faster than pure Python (up to millions of times faster on a GPU!).\n",
    "\n",
    "NOTE: The tuple `(-1,-2)` represents a range of axes. In Python, `-1` refers to the last element, and `-2` refers to the second-to-last. So in this case, this tells PyTorch that we want to take the mean ranging over the values indexed by the last two axes of the tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e46ab3-3907-4df3-b54b-14594081f257",
   "metadata": {},
   "source": [
    "To figure out whether an image is a 3 or not by using the following logic: if the distance between the digit in question and the ideal 3 is less than the distance to the ideal 7, then it's a 3. This function will automatically do broadcasting and be applied elementwise, just like all PyTorch functions and operators:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea8d8c6-cd52-45bf-bd6e-787ba7cd7721",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5093ff76-8940-4d5c-b0d0-a45e89d07f89",
   "metadata": {},
   "source": [
    "## An end to end SGD example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91dec7f-c7bd-4981-884e-7ae1ead5d291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "time = torch.arange(0,20).float()\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a88a7f-71a7-4d2e-8f71-7ca8a809baa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1\n",
    "plt.scatter(time,speed);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed9200-9b4e-4856-8478-8a97a976d2e7",
   "metadata": {},
   "source": [
    "Let's try to create a model for above data. We need to find a quadratic function which can predict the values accrately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a2ca0-6830-488c-831b-b153897f8426",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def f(t, params):\n",
    "    a,b,c = params\n",
    "    return a*(t**2) + (b*t) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a6ee9e-b4a6-42b2-bdec-fdd37e0f696f",
   "metadata": {},
   "source": [
    "Choose a loss function, which will return a values based on a prediction and a target. For continuous data, it's common to use *mean squared error*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8663b-4833-45c6-87e1-46c272e08fb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loss function\n",
    "def mse(preds, targets): \n",
    "    return ((preds-targets)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245b996-ee87-43de-8226-d2a63b422e88",
   "metadata": {},
   "source": [
    "let's work through our 7 step process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008b4de5-8511-49b0-a05c-7a742fcdad50",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 1: Initialize the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaf0e65-9394-4b6b-9725-e2d457c16490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the parameters to random values\n",
    "params = torch.randn(3).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fef0d16-1343-4e77-bf86-75079d1fbdec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "orig_params = params.clone()\n",
    "orig_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00ee69c-7da8-4b05-a893-80046da95e32",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 2: Calculate the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bcd774-b35f-4795-b5b3-df70ed1eb1bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = f(time, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37a7e7c-1ab5-4885-9f29-4d3ee3cb073c",
   "metadata": {},
   "source": [
    "Let's create a little function to see how close our predictions are to our targets, and take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4deb44-f46e-4846-bf92-8cf6c3f85d1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_preds(preds, ax=None):\n",
    "    if ax is None: ax=plt.subplots()[1]\n",
    "    ax.scatter(time, speed)\n",
    "    ax.scatter(time, to_np(preds), color='red')\n",
    "    ax.set_ylim(-300,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b3e9c-1f03-4caf-aca4-fcf698feee47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3ec590-3f48-46e9-b95b-05aaa7ee23f1",
   "metadata": {},
   "source": [
    "#### Step 3: Calculate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12edc0f-732b-4aec-9232-bc303f3cbdb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss = mse(preds, speed)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5cd8d-ed44-4420-90ee-23f79ab91e1a",
   "metadata": {},
   "source": [
    "#### Step 4: Calculate the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bd0716-1976-4cdf-b803-a5987a8719e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "params.grad\n",
    "params.grad * 1e-5\n",
    "print(orig_params) \n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a70114-be27-43b3-add0-5c172250cc32",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 5: Step the weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5b4953-193d-442f-a0d0-003ebea3caf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# w := w - α [dJ(w)/dw] where α is learning rate\n",
    "lr = 1e-5\n",
    "params.data -= lr * params.grad.data\n",
    "params.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974b9abf-e576-4837-846d-9174b36ae09b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = f(time,params)\n",
    "mse(preds, speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87355b71-2a88-412f-b92f-26accb1dce07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfb817f-b72b-4810-83d2-c4f2507c603c",
   "metadata": {},
   "source": [
    "We need to repeat this a few times, so we'll create a function to apply one step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421f037-940f-463b-beb0-ed3d1b9b2db9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def apply_step(params, prn=True):\n",
    "    preds = f(time, params)\n",
    "    loss = mse(preds, speed)\n",
    "    loss.backward()\n",
    "    params.data -= lr * params.grad.data      # w := w - α [dJ(w)/dw] where α is learning rate\n",
    "    params.grad = None\n",
    "    if prn: print(loss.item())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb334a3-8e53-455a-a548-6f4d8464073a",
   "metadata": {},
   "source": [
    "#### Step 6: Repeat the process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7171d-9afe-43d0-851d-1f82274d0638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(10): \n",
    "    apply_step(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a820a0-aa0a-44d4-9664-cd8a188ed524",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_,axs = plt.subplots(1,4,figsize=(12,3))\n",
    "for ax in axs: show_preds(apply_step(params, False), ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2f9711-bc0b-4b48-b287-5eaa04d7ee75",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Step 7: stop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e9a75b-a471-45bb-a67f-efa19f45d981",
   "metadata": {},
   "source": [
    "We just decided to stop after 10 epochs arbitrarily. In practice, we would watch the training and validation losses and our metrics to decide when to stop, as we've discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685de77d-ba45-41de-89dc-7b09dc334218",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### All together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb1917-6b3a-46d9-b06c-7e70c32484d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def f(t, params):\n",
    "    a,b,c = params\n",
    "    return a*(t**2) + (b*t) + c\n",
    "\n",
    "# Loss function\n",
    "def mse(preds, targets): \n",
    "    return ((preds-targets)**2).mean()\n",
    "\n",
    "time = torch.arange(0,20).float()\n",
    "speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1   # Labels/y/original values\n",
    "\n",
    "\n",
    "def apply_step(params, prn=True):\n",
    "    preds = f(time, params)\n",
    "    loss = mse(preds, speed)\n",
    "    loss.backward()\n",
    "    params.data -= lr * params.grad.data\n",
    "    params.grad = None\n",
    "    if prn: print(loss.item())\n",
    "    return preds\n",
    "\n",
    "params = torch.randn(3).requires_grad_()  # Randomly initialize the parameters\n",
    "for i in range(10): \n",
    "    apply_step(params)\n",
    "    \n",
    "_,axs = plt.subplots(1,4,figsize=(12,3))\n",
    "for ax in axs: show_preds(apply_step(params, False), ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5203e-ff38-4fff-8472-c6f80cc5b0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_fastaicourse",
   "language": "python",
   "name": "conda_fastaicourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
