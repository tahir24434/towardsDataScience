{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f973c521-6580-4e59-9f06-17f57adf0982",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedfe9bc-8f3b-467b-8e74-42f7273ac1e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from fastbook import *\n",
    "from fastai.vision.widgets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60baf8a-cccf-4882-bcc3-36f4331b17f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bear_types = 'grizzly','black','teddy'\n",
    "path = Path('bears')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12807d0-a387-4d3b-8a03-8d400c1da321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not path.exists():\n",
    "    path.mkdir()\n",
    "    for bt in bear_types:\n",
    "        dest = (path/bt)\n",
    "        dest.mkdir(exist_ok=True)\n",
    "        urls = search_images_ddg(f'{bt} bear')\n",
    "        download_images(dest, urls=urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd214406-e3fd-401f-a6e6-20776b213418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fns = get_image_files(path)\n",
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba484aa-5579-406e-bb9d-6b025fd5b016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "failed = verify_images(fns)\n",
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817e155f-b809-4894-920d-c110cf89d817",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "failed.map(Path.unlink)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fbd9b5-2b6a-4e94-b79b-961c4ceac08b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "??verify_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c43859b-7345-40ba-bedc-26b090e0802a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## From data to dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468fef15-f72a-4999-a207-b60ccaa71878",
   "metadata": {},
   "source": [
    "To train a model, we'll need `DataLoaders`, which is an iterator that provides a stream of mini-batches, where each mini-batch is a couple of batches of independent variables and a batch of dependent variables.\n",
    "\n",
    "To build a DataBlock, there are several steps that needs to be followed. These steps can be asked in the form of questions \n",
    "1. What is the types of your input/labels? `Blocks`\n",
    "2. Where is your data? `get_items`\n",
    "3. Does something need to be applied to inputs/labels? `get_x, get_y`\n",
    "4. How to split the data? `splitter`\n",
    "5. Do we need to apply something on formed items? `item_tfms`\n",
    "6. Do we need to apply something on formed batches? `batch_tfms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08b4ad2-3daa-41f3-80f7-7f742eb28859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataBlock: Generic container to quickly build Datasets and DataLoaders.\n",
    "#            blocks(List): One or more Transform blocks.\n",
    "#                          blocks are used to define a pre-defined problem domain.\n",
    "#                          e.g, ImageBlock, CategoryBlock, MultiCategoryBlock, TextBlock etc\n",
    "#                          CategoryBlock: TransformBlock for single-label categorical targets\n",
    "#            get_items:    Where is the data?\n",
    "#                          We can use get_image_files function to go grab all the file locations \n",
    "#                          of our images.\n",
    "#            get_y:        How you extract labels. \n",
    "#            splitter:     How to split your data. This is usually a random split between the training and \n",
    "#                          validation dataset.\n",
    "#            item_tfms:    Item transform applied on an individual item basis. This is done on the CPU.\n",
    "\n",
    "bears = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock), \n",
    "    get_items=get_image_files, \n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1c6bd-b5ed-4dcc-ab0a-d2d6b1f60ed9",
   "metadata": {},
   "source": [
    "Above command has given us a DataBlock object. This is like a template for creating a DataLoaders. We still need to tell fastai the actual source of our dataâ€”in this case, the path where the images can be found:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10166a5-7399-4c1c-92a4-0e5962ee5a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dls = bears.dataloaders(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f637d-4dab-4136-8cb4-886c18a9df0f",
   "metadata": {},
   "source": [
    "A `DataLoaders` includes **validation** and **training** `DataLoader`s. `DataLoader` is a class that provides batches of a few items at a time to the GPU. We'll be learning a lot more about this class in the next chapter. When you loop through a `DataLoader` fastai will give you 64 (by default) items at a time, all stacked up into a single tensor. We can take a look at a few of those items by calling the `show_batch` method on a `DataLoader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78aa0e95-ef0b-44f0-8e55-5c38c6bf1bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dls.valid.show_batch(max_n=4, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51505523-1246-4d88-8a3b-38ed72e44196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bears = bears.new(item_tfms=Resize(128, ResizeMethod.Squish))\n",
    "dls = bears.dataloaders(path)\n",
    "dls.valid.show_batch(max_n=4, nrows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698f23a0-605b-4086-ade1-c8bd80413884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In practice, below is used\n",
    "bears = bears.new(\n",
    "    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n",
    "    batch_tfms=aug_transforms()\n",
    ")\n",
    "dls = bears.dataloaders(path)\n",
    "dls.train.show_batch(max_n=4, nrows=1, unique=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa8d980-85bb-495c-97a8-41b386bb97d6",
   "metadata": {},
   "source": [
    "## Training Your Model, and Using It to Clean Your Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e78dd-4d51-4b7d-8551-e4c85532e66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40efb74e-3297-4c3f-9685-ff2b4e157370",
   "metadata": {},
   "source": [
    "Now let's see whether the mistakes the model is making are mainly thinking that grizzlies are teddies (that would be bad for safety!), or that grizzlies are black bears, or something else. To visualize this, we can create a *confusion matrix*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f827c4-7d94-4b8f-8a6d-ca73b55e3466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a50431f-2625-4fac-981e-86b4e2bf4e80",
   "metadata": {},
   "source": [
    "It's helpful to see where exactly our errors are occurring, to see whether they're due to a dataset problem (e.g., images that aren't bears at all, or are labeled incorrectly, etc.), or a model problem (perhaps it isn't handling images taken with unusual lighting, or from a different angle, etc.). To do this, we can sort our images by their *loss*.\n",
    "\n",
    "The loss is a number that is higher if the model is incorrect (especially if it's also confident of its incorrect answer), or if it's correct, but not confident of its correct answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e9011-20cb-487d-af80-bb2caef86b64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interp.plot_top_losses(5, nrows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d977e-dcbc-4f5e-8308-9b7933461abb",
   "metadata": {},
   "source": [
    "fastai includes a handy GUI for data cleaning called `ImageClassifierCleaner` that allows you to choose a category and the training versus validation set and view the highest-loss images (in order), along with menus to allow images to be selected for removal or relabeling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5b999f-bf7e-4625-b3b2-9b6841b57126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hide_output\n",
    "cleaner = ImageClassifierCleaner(learn)\n",
    "cleaner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1062cb1f-409f-43aa-8f7d-a20fdaf43478",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Turning Your Model into an Online Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec66242-b18d-431a-95d1-9c3dcc8a65e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_fastaicourse",
   "language": "python",
   "name": "conda_fastaicourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
