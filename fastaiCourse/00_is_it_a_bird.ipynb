{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "681f3482-fc32-4115-b8ce-577b3bac723a",
   "metadata": {},
   "source": [
    "## Is it a bird?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a33161-bd5a-423a-9e58-3aad6f57371c",
   "metadata": {
    "tags": []
   },
   "source": [
    "The basic steps we'll take are:\n",
    "\n",
    "1. Use DuckDuckGo to search for images of \"bird photos\"\n",
    "1. Use DuckDuckGo to search for images of \"forest photos\"\n",
    "1. Fine-tune a pretrained neural network to recognise these two groups\n",
    "1. Try running this model on a picture of a bird and see if it works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f585b31a-036a-498e-b62e-2c89ca6227c0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 1: Download images of birds and non-birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94b5bf-4d97-406f-8d70-b18af82c32c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from duckduckgo_search import ddg_images\n",
    "from fastcore.all import *\n",
    "\n",
    "def search_images(term, max_results=200):\n",
    "    # ddg_images: returns Optional[List[dict]]: DuckDuckGo text search results.\n",
    "    # example return: {'height': 2400, 'image': 'http://etc.usf.edu/clipart/13500/13570/liberty-tree_13570.tif', 'source': 'Bing', 'thumbnail': 'https://tse2.mm.bing.net/th?id=OIP.4t3AojTiUP6TZ-AFaSfCHAHaJ7&pid=Api', 'title': 'Liberty Tree | ClipArt ETC', 'url': 'http://etc.usf.edu/clipart/13500/13570/liberty-tree_13570.htm', 'width': 1790},\n",
    "    # L: https://fastcore.fast.ai/foundation.html#l\n",
    "    # L.itemgot: Create new L with item idx of all items\n",
    "    return L(ddg_images(term, max_results=max_results)).itemgot('image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d3bb0-1cf1-4b31-82cb-a4793290f89e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "urls = search_images('forest photos', max_results=1)\n",
    "urls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a990dca-acf9-4b7f-b079-938c02e18734",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://fastdownload.fast.ai/core.html#download_url\n",
    "from fastdownload import download_url\n",
    "dest = 'forest.jpg'\n",
    "fpath = download_url(urls[0], dest, show_progress=False)\n",
    "\n",
    "from fastai.vision.all import *\n",
    "im = Image.open(fpath)\n",
    "im.to_thumb(256,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b0101-48a1-4ee2-86c8-903ef38fec6d",
   "metadata": {},
   "source": [
    "Let's grab 200 examples of each of birds and forest photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc7c470-0677-4dfc-b44a-ab6870570e91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# download_images: https://docs.fast.ai/vision.utils.html\n",
    "\n",
    "searchQueries = 'forest','bird'\n",
    "path = Path('bird_or_not')\n",
    "from time import sleep\n",
    "\n",
    "for sq in searchQueries:\n",
    "    dest = (path/sq)\n",
    "    dest.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    urls = search_images(f'{sq} photo')\n",
    "    download_images(dest, urls=urls)\n",
    "    sleep(10)  # Pause between searches to avoid over-loading server\n",
    "    urls = search_images(f'{sq} sun photo')\n",
    "    download_images(dest, urls=urls)\n",
    "    sleep(10)  \n",
    "    urls = search_images(f'{sq} shade photo')\n",
    "    download_images(dest, urls=urls)\n",
    "    resize_images(path/sq, max_size=400, dest=path/sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4220dc-7a8d-4e1d-b289-d2cd49ad5d73",
   "metadata": {},
   "source": [
    "## Step 2: Train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce3a763-a0ac-48a6-9d9c-e42f28dc5dd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Vision utils: https://docs.fast.ai/vision.utils.html\n",
    "# L: https://fastcore.fast.ai/foundation.html#l\n",
    "\n",
    "# Get image files in path recursively, only in folders, if specified.\n",
    "imfiles = get_image_files(path)\n",
    "\n",
    "# Find images in fns that canâ€™t be opened\n",
    "failed = verify_images(imfiles)\n",
    "# Create new L with f applied to all items. unlink: Remove this file or symbolic link\n",
    "failed.map(Path.unlink)        \n",
    "len(failed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dfbe97-c804-469d-bc9a-765e64a88b1d",
   "metadata": {},
   "source": [
    "To train a model, we'll need `DataLoaders`, which is an iterator that provides a stream of mini-batches, where each mini-batch is a couple of batches of independent variables and a batch of dependent variables.\n",
    "\n",
    "To build a DataBlock, there are several steps that needs to be followed. These steps can be asked in the form of questions \n",
    "1. What is the types of your input/labels? `Blocks`\n",
    "2. Where is your data? `get_items`\n",
    "3. Does something need to be applied to inputs/labels? `get_x, get_y`\n",
    "4. How to split the data? `splitter`\n",
    "5. Do we need to apply something on formed items? `item_tfms`\n",
    "6. Do we need to apply something on formed batches? `batch_tfms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845075c-b9b7-42ac-ae6b-0a0936afdd8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataBlock: Generic container to quickly build Datasets and DataLoaders.\n",
    "#            blocks(List): One or more Transform blocks.\n",
    "#                          blocks are used to define a pre-defined problem domain.\n",
    "#                          e.g, ImageBlock, CategoryBlock, MultiCategoryBlock, TextBlock etc\n",
    "#                          CategoryBlock: TransformBlock for single-label categorical targets\n",
    "#            get_items:    Where is the data?\n",
    "#                          We can use get_image_files function to go grab all the file locations \n",
    "#                          of our images.\n",
    "#            get_y:        How you extract labels. \n",
    "#            splitter:     How to split your data. This is usually a random split between the training and \n",
    "#                          validation dataset.\n",
    "#            item_tfms:    Item transform applied on an individual item basis. This is done on the CPU.\n",
    "\n",
    "dls = DataBlock(\n",
    "    # The inputs to our model are images, and the outputs are categories\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    # To find all the inputs to our model, run the get_image_files function (which returns a list of all image files in a path).\n",
    "    get_items=get_image_files,\n",
    "    # The labels (y values) is the name of the parent of each file (i.e. the name of the folder they're in, which will be bird or forest).\n",
    "    get_y=parent_label,\n",
    "    # Split the data into training and validation sets randomly, using 20% of the data for the validation set.\n",
    "    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    # Before training, resize each image to 192x192 pixels by \"squishing\" it (as opposed to cropping it).\n",
    "    item_tfms=[Resize(192, method='squish')]\n",
    ").dataloaders(path)\n",
    "dls.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a920ab-de3c-4ad3-9830-42d098ea97a4",
   "metadata": {},
   "source": [
    "Now we're ready to train our model. The fastest widely used computer vision model is `resnet18`. \n",
    "fastai comes with a helpful `fine_tune()` method which automatically uses best practices for fine tuning pre-trained model, so we'll use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0042d6-9fd1-4e92-8139-21bd29567f06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=error_rate)\n",
    "learn.fine_tune(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93b39e0-c78f-42db-93bb-22b36c763c05",
   "metadata": {},
   "source": [
    "\"Fine-tuning\" a model means that we're starting with a model someone else has trained using some other dataset (called the *pretrained model*), and adjusting the weights a little bit so that the model learns to recognise your particular dataset. In this case, the pretrained model was trained to recognise photos in *imagenet*, and widely-used computer vision dataset with images covering 1000 categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a29f550-bc17-401d-9313-ce4de5b0c7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Step 3: Use our model (and build your own!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8db30bc-6aa0-4476-b4f7-3ea2d52fd5a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_bird, _, probs = learn.predict('frst.jpg')\n",
    "print(f\"This is a: {is_bird}.\")\n",
    "print(f\"Probability it's a bird: {probs[0]:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7614f2-9b01-4307-8e9e-80abd17ecf43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbca8bd-f069-447b-bcd3-9138ada6f96c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_fastaicourse",
   "language": "python",
   "name": "conda_fastaicourse"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
